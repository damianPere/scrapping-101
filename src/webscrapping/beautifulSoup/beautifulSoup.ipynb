{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9KI28Q2S0l0q"
      },
      "source": [
        "## Metodo con BeautifulSoup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sK7w-X2t92g2"
      },
      "outputs": [],
      "source": [
        "import requests # Importamos la librería requests para realizar solicitudes HTTP\n",
        "from bs4 import BeautifulSoup # Importamos BeautifulSoup de bs4 para analizar documentos HTML y XML\n",
        "import pprint # Importamos pprint para imprimir estructuras de datos de manera legible\n",
        "\n",
        "# Función para realizar la búsqueda de un producto y obtener las primeras 10 URLs de resultados\n",
        "def obtener_urls_productos(busqueda, cantidad=10):\n",
        "    try:\n",
        "        # Construimos la URL de búsqueda con el término proporcionado\n",
        "        url_busqueda = f\"https://listado.mercadolibre.com.co/{busqueda}\"\n",
        "\n",
        "        response = requests.get(url, timeout=10)\n",
        "        response.raise_for_status()\n",
        "\n",
        "        # Enviamos una solicitud GET a la URL de búsqueda\n",
        "        response = requests.get(url_busqueda)\n",
        "\n",
        "        # Guardamos el contenido HTML para inspección\n",
        "        with open(\"pagina_portatil.html\", \"w\", encoding='utf-8') as file:\n",
        "          file.write(response.text)\n",
        "\n",
        "\n",
        "        # Analizamos el contenido HTML de la respuesta\n",
        "        soup = BeautifulSoup(response.content, 'html.parser')\n",
        "\n",
        "        # Encontramos los elementos de la lista de resultados de búsqueda\n",
        "        items = soup.find_all('li', class_='ui-search-layout__item', limit=cantidad)\n",
        "        # Obtenemos los enlaces de los productos\n",
        "        urls = [item.find('a', href=True)['href'] for item in items if item.find('a', href=True)]\n",
        "\n",
        "        # Retornamos la lista de URLs\n",
        "        return urls\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        print(f\"Error al realizar la solicitud: {e}\")\n",
        "        return []\n",
        "\n",
        "# Función para obtener los detalles de un producto\n",
        "def obtener_detalles_producto(url_producto):\n",
        "    try:\n",
        "        # Enviamos una solicitud GET a la URL del producto\n",
        "        response = requests.get(url_producto)\n",
        "        # Analizamos el contenido HTML de la página del producto\n",
        "        soup = BeautifulSoup(response.content, 'html.parser')\n",
        "\n",
        "        # Creamos un diccionario para almacenar los datos del producto\n",
        "        data = {}\n",
        "\n",
        "        # Extraemos la categoría del producto\n",
        "        category = soup.find('div', class_='ui-pdp-breadcrumb')\n",
        "        data['Categoria'] = category.get_text(strip=True) if category else None\n",
        "\n",
        "        # Extraemos el título del producto\n",
        "        title = soup.find('h1', class_='ui-pdp-title')\n",
        "        data['Titulo'] = title.get_text(strip=True) if title else None\n",
        "\n",
        "        # Extraemos el precio del producto\n",
        "        price_div = soup.find('div', class_='ui-pdp-price__second-line')\n",
        "        price = price_div.find('span', class_='andes-money-amount__fraction') if price_div else None\n",
        "        data['Precio'] = price.get_text(strip=True) if price else None\n",
        "\n",
        "        # Buscamos un elemento que indique si hay un descuento\n",
        "        discount = soup.find('s', {'role': 'img', 'aria-label': lambda x: x and x.startswith('Antes:')})\n",
        "        data['Descuento'] = bool(discount)\n",
        "\n",
        "        # Extraemos el nombre del vendedor\n",
        "        seller_button = soup.find('button', class_='ui-pdp-seller__link-trigger-button non-selectable')\n",
        "        seller = seller_button.find_all('span')[1].get_text(strip=True) if seller_button else None\n",
        "        data['Vendedor'] = seller\n",
        "\n",
        "        # Extraemos la calificación promedio del producto\n",
        "        rating = soup.find('span', {'aria-hidden': 'true', 'class': 'ui-pdp-review__rating'})\n",
        "        data['Calificacion promedio'] = rating.get_text(strip=True) if rating else None\n",
        "\n",
        "        # Extraemos la cantidad de calificaciones\n",
        "        reviews_count = soup.find('span', {'aria-hidden': 'true', 'class': 'ui-pdp-review__amount'})\n",
        "        data['Cantidad de Calificaciones'] = reviews_count.get_text(strip=True) if reviews_count else None\n",
        "\n",
        "        # Extraemos la garantía del producto\n",
        "        warranty = soup.find('p', class_='ui-pdp-family--REGULAR ui-pdp-media__title', string=lambda text: text and text.endswith('garant√≠a de f√°brica.'))\n",
        "        data['Garantia'] = warranty.get_text(strip=True) if warranty else None\n",
        "\n",
        "        # Extraemos la descripción del producto\n",
        "        description = soup.find('p', class_='ui-pdp-description__content')\n",
        "        data['Descripcion'] = description.get_text(strip=True) if description else None\n",
        "\n",
        "        # Extraemos información de stock\n",
        "        stock_info = soup.find('p', class_='ui-pdp-stock-information__title')\n",
        "        data['Stock'] = stock_info.get_text(strip=True) if stock_info else None\n",
        "\n",
        "        # Extraemos la cantidad total de opiniones\n",
        "        total_opinions = soup.find('span', class_='total-opinion')\n",
        "        data['Cantidad de Opiniones'] = total_opinions.get_text(strip=True) if total_opinions else None\n",
        "\n",
        "        # Extraemos el número de publicación del producto\n",
        "        publication_number = soup.find('span', class_='ui-pdp-color--BLACK ui-pdp-family--SEMIBOLD')\n",
        "        data['Numero de Publicacion'] = publication_number.get_text(strip=True) if publication_number else None\n",
        "\n",
        "        # Agregamos la URL del producto al diccionario\n",
        "        data['URL del Producto'] = url_producto\n",
        "\n",
        "        # Retornamos el diccionario con los datos del producto\n",
        "        return data\n",
        "    except Exception as e:\n",
        "        print(f\"Error al procesar un producto: {e}\")\n",
        "        return {}\n",
        "\n",
        "# Realizamos la búsqueda y obtenemos los detalles de los productos\n",
        "busqueda = 'portatil'\n",
        "# Primero, obtenemos las URLs de los primeros 10 productos encontrados\n",
        "urls_productos = obtener_urls_productos(busqueda)\n",
        "\n",
        "# Lista para almacenar los detalles de cada producto\n",
        "detalles_productos = []\n",
        "\n",
        "# Iteramos sobre cada URL y obtenemos los detalles del producto\n",
        "for url in urls_productos:\n",
        "    detalles_producto = obtener_detalles_producto(url)\n",
        "    detalles_productos.append(detalles_producto)\n",
        "\n",
        "# Finalmente, imprimimos los detalles de todos los productos de manera legible\n",
        "pprint.pprint(detalles_productos)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
